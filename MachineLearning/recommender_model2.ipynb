{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9866 images belonging to 11 classes.\n",
      "Found 3430 images belonging to 11 classes.\n",
      "Found 3347 images belonging to 11 classes.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_6      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,419</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m1,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv3 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m1,180,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv3 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv3 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_6      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m65,664\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)             │         \u001b[38;5;34m1,419\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,781,771</span> (56.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,781,771\u001b[0m (56.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">67,083</span> (262.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m67,083\u001b[0m (262.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> (56.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m14,714,688\u001b[0m (56.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "Batch 10: Loss = 10.0156, Accuracy = 0.1125\n",
      "Batch 20: Loss = 7.2928, Accuracy = 0.1609\n",
      "Batch 30: Loss = 6.0095, Accuracy = 0.1594\n",
      "Batch 40: Loss = 5.1409, Accuracy = 0.1750\n",
      "Batch 50: Loss = 4.5941, Accuracy = 0.1813\n",
      "Batch 60: Loss = 4.2105, Accuracy = 0.1958\n",
      "Batch 70: Loss = 3.9240, Accuracy = 0.2076\n",
      "Batch 80: Loss = 3.7129, Accuracy = 0.2141\n",
      "Batch 90: Loss = 3.5457, Accuracy = 0.2215\n",
      "Batch 100: Loss = 3.4039, Accuracy = 0.2266\n",
      "Batch 110: Loss = 3.2919, Accuracy = 0.2315\n",
      "Batch 120: Loss = 3.1882, Accuracy = 0.2393\n",
      "Batch 130: Loss = 3.1101, Accuracy = 0.2438\n",
      "Batch 140: Loss = 3.0470, Accuracy = 0.2433\n",
      "Batch 150: Loss = 2.9817, Accuracy = 0.2473\n",
      "Batch 160: Loss = 2.9268, Accuracy = 0.2514\n",
      "Batch 170: Loss = 2.8788, Accuracy = 0.2540\n",
      "Batch 180: Loss = 2.8418, Accuracy = 0.2564\n",
      "Batch 190: Loss = 2.7989, Accuracy = 0.2581\n",
      "Batch 200: Loss = 2.7618, Accuracy = 0.2606\n",
      "Batch 210: Loss = 2.7195, Accuracy = 0.2665\n",
      "Batch 220: Loss = 2.6822, Accuracy = 0.2702\n",
      "Batch 230: Loss = 2.6557, Accuracy = 0.2720\n",
      "Batch 240: Loss = 2.6250, Accuracy = 0.2776\n",
      "Batch 250: Loss = 2.5981, Accuracy = 0.2809\n",
      "Batch 260: Loss = 2.5691, Accuracy = 0.2855\n",
      "Batch 270: Loss = 2.5459, Accuracy = 0.2875\n",
      "Batch 280: Loss = 2.5221, Accuracy = 0.2901\n",
      "Batch 290: Loss = 2.4969, Accuracy = 0.2944\n",
      "Batch 300: Loss = 2.4735, Accuracy = 0.2977\n",
      "Training - Loss: 2.4616, Accuracy: 0.2986\n",
      "Validation - Loss: 1.5949, Accuracy: 0.4393\n",
      "Epoch 2/30\n",
      "Batch 10: Loss = 1.8128, Accuracy = 0.3781\n",
      "Batch 20: Loss = 1.8563, Accuracy = 0.3766\n",
      "Batch 30: Loss = 1.8695, Accuracy = 0.3667\n",
      "Batch 40: Loss = 1.8428, Accuracy = 0.3750\n",
      "Batch 50: Loss = 1.8283, Accuracy = 0.3844\n",
      "Batch 60: Loss = 1.7987, Accuracy = 0.3891\n",
      "Batch 70: Loss = 1.7938, Accuracy = 0.3888\n",
      "Batch 80: Loss = 1.7895, Accuracy = 0.3938\n",
      "Batch 90: Loss = 1.7822, Accuracy = 0.3951\n",
      "Batch 100: Loss = 1.7705, Accuracy = 0.4038\n",
      "Batch 110: Loss = 1.7572, Accuracy = 0.4054\n",
      "Batch 120: Loss = 1.7560, Accuracy = 0.4076\n",
      "Batch 130: Loss = 1.7478, Accuracy = 0.4113\n",
      "Batch 140: Loss = 1.7490, Accuracy = 0.4112\n",
      "Batch 150: Loss = 1.7491, Accuracy = 0.4135\n",
      "Batch 160: Loss = 1.7566, Accuracy = 0.4104\n",
      "Batch 170: Loss = 1.7528, Accuracy = 0.4110\n",
      "Batch 180: Loss = 1.7485, Accuracy = 0.4125\n",
      "Batch 190: Loss = 1.7422, Accuracy = 0.4156\n",
      "Batch 200: Loss = 1.7370, Accuracy = 0.4164\n",
      "Batch 210: Loss = 1.7419, Accuracy = 0.4150\n",
      "Batch 220: Loss = 1.7428, Accuracy = 0.4151\n",
      "Batch 230: Loss = 1.7384, Accuracy = 0.4168\n",
      "Batch 240: Loss = 1.7336, Accuracy = 0.4190\n",
      "Batch 250: Loss = 1.7293, Accuracy = 0.4219\n",
      "Batch 260: Loss = 1.7268, Accuracy = 0.4215\n",
      "Batch 270: Loss = 1.7251, Accuracy = 0.4231\n",
      "Batch 280: Loss = 1.7227, Accuracy = 0.4241\n",
      "Batch 290: Loss = 1.7199, Accuracy = 0.4259\n",
      "Batch 300: Loss = 1.7120, Accuracy = 0.4274\n",
      "Training - Loss: 1.7128, Accuracy: 0.4279\n",
      "Validation - Loss: 1.2323, Accuracy: 0.5999\n",
      "Epoch 3/30\n",
      "Batch 10: Loss = 1.4368, Accuracy = 0.5281\n",
      "Batch 20: Loss = 1.5074, Accuracy = 0.5031\n",
      "Batch 30: Loss = 1.5410, Accuracy = 0.4865\n",
      "Batch 40: Loss = 1.5427, Accuracy = 0.4844\n",
      "Batch 50: Loss = 1.5472, Accuracy = 0.4856\n",
      "Batch 60: Loss = 1.5505, Accuracy = 0.4786\n",
      "Batch 70: Loss = 1.5502, Accuracy = 0.4746\n",
      "Batch 80: Loss = 1.5433, Accuracy = 0.4766\n",
      "Batch 90: Loss = 1.5400, Accuracy = 0.4760\n",
      "Batch 100: Loss = 1.5429, Accuracy = 0.4787\n",
      "Batch 110: Loss = 1.5409, Accuracy = 0.4801\n",
      "Batch 120: Loss = 1.5402, Accuracy = 0.4833\n",
      "Batch 130: Loss = 1.5375, Accuracy = 0.4820\n",
      "Batch 140: Loss = 1.5299, Accuracy = 0.4824\n",
      "Batch 150: Loss = 1.5291, Accuracy = 0.4840\n",
      "Batch 160: Loss = 1.5265, Accuracy = 0.4857\n",
      "Batch 170: Loss = 1.5182, Accuracy = 0.4886\n",
      "Batch 180: Loss = 1.5112, Accuracy = 0.4908\n",
      "Batch 190: Loss = 1.5031, Accuracy = 0.4939\n",
      "Batch 200: Loss = 1.5014, Accuracy = 0.4947\n",
      "Batch 210: Loss = 1.5020, Accuracy = 0.4939\n",
      "Batch 220: Loss = 1.5036, Accuracy = 0.4930\n",
      "Batch 230: Loss = 1.5047, Accuracy = 0.4929\n",
      "Batch 240: Loss = 1.5085, Accuracy = 0.4926\n",
      "Batch 250: Loss = 1.5088, Accuracy = 0.4919\n",
      "Batch 260: Loss = 1.5075, Accuracy = 0.4922\n",
      "Batch 270: Loss = 1.5054, Accuracy = 0.4921\n",
      "Batch 280: Loss = 1.5073, Accuracy = 0.4923\n",
      "Batch 290: Loss = 1.5077, Accuracy = 0.4919\n",
      "Batch 300: Loss = 1.5056, Accuracy = 0.4928\n",
      "Training - Loss: 1.5045, Accuracy: 0.4926\n",
      "Validation - Loss: 1.1524, Accuracy: 0.6155\n",
      "Epoch 4/30\n",
      "Batch 10: Loss = 1.3613, Accuracy = 0.5250\n",
      "Batch 20: Loss = 1.4147, Accuracy = 0.5156\n",
      "Batch 30: Loss = 1.4149, Accuracy = 0.5292\n",
      "Batch 40: Loss = 1.3758, Accuracy = 0.5406\n",
      "Batch 50: Loss = 1.3586, Accuracy = 0.5431\n",
      "Batch 60: Loss = 1.3695, Accuracy = 0.5370\n",
      "Batch 70: Loss = 1.3857, Accuracy = 0.5308\n",
      "Batch 80: Loss = 1.3818, Accuracy = 0.5332\n",
      "Batch 90: Loss = 1.3902, Accuracy = 0.5326\n",
      "Batch 100: Loss = 1.3924, Accuracy = 0.5300\n",
      "Batch 110: Loss = 1.3900, Accuracy = 0.5304\n",
      "Batch 120: Loss = 1.3922, Accuracy = 0.5281\n",
      "Batch 130: Loss = 1.3953, Accuracy = 0.5296\n",
      "Batch 140: Loss = 1.3962, Accuracy = 0.5290\n",
      "Batch 150: Loss = 1.3931, Accuracy = 0.5279\n",
      "Batch 160: Loss = 1.3882, Accuracy = 0.5289\n",
      "Batch 170: Loss = 1.3922, Accuracy = 0.5287\n",
      "Batch 180: Loss = 1.3881, Accuracy = 0.5300\n",
      "Batch 190: Loss = 1.3906, Accuracy = 0.5296\n",
      "Batch 200: Loss = 1.3930, Accuracy = 0.5289\n",
      "Batch 210: Loss = 1.3942, Accuracy = 0.5293\n",
      "Batch 220: Loss = 1.3936, Accuracy = 0.5286\n",
      "Batch 230: Loss = 1.3950, Accuracy = 0.5296\n",
      "Batch 240: Loss = 1.3949, Accuracy = 0.5305\n",
      "Batch 250: Loss = 1.3971, Accuracy = 0.5305\n",
      "Batch 260: Loss = 1.3967, Accuracy = 0.5310\n",
      "Batch 270: Loss = 1.3985, Accuracy = 0.5309\n",
      "Batch 280: Loss = 1.3975, Accuracy = 0.5302\n",
      "Batch 290: Loss = 1.3956, Accuracy = 0.5297\n",
      "Batch 300: Loss = 1.4000, Accuracy = 0.5301\n",
      "Training - Loss: 1.3995, Accuracy: 0.5296\n",
      "Validation - Loss: 1.0294, Accuracy: 0.6654\n",
      "Epoch 5/30\n",
      "Batch 10: Loss = 1.1715, Accuracy = 0.5844\n",
      "Batch 20: Loss = 1.2985, Accuracy = 0.5641\n",
      "Batch 30: Loss = 1.3278, Accuracy = 0.5562\n",
      "Batch 40: Loss = 1.3441, Accuracy = 0.5586\n",
      "Batch 50: Loss = 1.3276, Accuracy = 0.5606\n",
      "Batch 60: Loss = 1.3390, Accuracy = 0.5547\n",
      "Batch 70: Loss = 1.3285, Accuracy = 0.5598\n",
      "Batch 80: Loss = 1.3276, Accuracy = 0.5590\n",
      "Batch 90: Loss = 1.3320, Accuracy = 0.5528\n",
      "Batch 100: Loss = 1.3380, Accuracy = 0.5503\n",
      "Batch 110: Loss = 1.3410, Accuracy = 0.5489\n",
      "Batch 120: Loss = 1.3431, Accuracy = 0.5456\n",
      "Batch 130: Loss = 1.3452, Accuracy = 0.5447\n",
      "Batch 140: Loss = 1.3496, Accuracy = 0.5433\n",
      "Batch 150: Loss = 1.3473, Accuracy = 0.5435\n",
      "Batch 160: Loss = 1.3477, Accuracy = 0.5430\n",
      "Batch 170: Loss = 1.3423, Accuracy = 0.5445\n",
      "Batch 180: Loss = 1.3466, Accuracy = 0.5455\n",
      "Batch 190: Loss = 1.3460, Accuracy = 0.5456\n",
      "Batch 200: Loss = 1.3391, Accuracy = 0.5477\n",
      "Batch 210: Loss = 1.3366, Accuracy = 0.5494\n",
      "Batch 220: Loss = 1.3381, Accuracy = 0.5503\n",
      "Batch 230: Loss = 1.3390, Accuracy = 0.5495\n",
      "Batch 240: Loss = 1.3403, Accuracy = 0.5490\n",
      "Batch 250: Loss = 1.3405, Accuracy = 0.5495\n",
      "Batch 260: Loss = 1.3378, Accuracy = 0.5502\n",
      "Batch 270: Loss = 1.3361, Accuracy = 0.5510\n",
      "Batch 280: Loss = 1.3317, Accuracy = 0.5520\n",
      "Batch 290: Loss = 1.3250, Accuracy = 0.5545\n",
      "Batch 300: Loss = 1.3211, Accuracy = 0.5561\n",
      "Training - Loss: 1.3206, Accuracy: 0.5568\n",
      "Validation - Loss: 1.0011, Accuracy: 0.6826\n",
      "Epoch 6/30\n",
      "Batch 10: Loss = 1.2948, Accuracy = 0.5750\n",
      "Batch 20: Loss = 1.2562, Accuracy = 0.5953\n",
      "Batch 30: Loss = 1.2374, Accuracy = 0.5969\n",
      "Batch 40: Loss = 1.2457, Accuracy = 0.5938\n",
      "Batch 50: Loss = 1.2333, Accuracy = 0.5906\n",
      "Batch 60: Loss = 1.2361, Accuracy = 0.5901\n",
      "Batch 70: Loss = 1.2440, Accuracy = 0.5893\n",
      "Batch 80: Loss = 1.2556, Accuracy = 0.5809\n",
      "Batch 90: Loss = 1.2607, Accuracy = 0.5760\n",
      "Batch 100: Loss = 1.2615, Accuracy = 0.5772\n",
      "Batch 110: Loss = 1.2706, Accuracy = 0.5767\n",
      "Batch 120: Loss = 1.2607, Accuracy = 0.5805\n",
      "Batch 130: Loss = 1.2613, Accuracy = 0.5793\n",
      "Batch 140: Loss = 1.2595, Accuracy = 0.5810\n",
      "Batch 150: Loss = 1.2634, Accuracy = 0.5779\n",
      "Batch 160: Loss = 1.2621, Accuracy = 0.5797\n",
      "Batch 170: Loss = 1.2662, Accuracy = 0.5798\n",
      "Batch 180: Loss = 1.2653, Accuracy = 0.5793\n",
      "Batch 190: Loss = 1.2629, Accuracy = 0.5796\n",
      "Batch 200: Loss = 1.2651, Accuracy = 0.5794\n",
      "Batch 210: Loss = 1.2619, Accuracy = 0.5807\n",
      "Batch 220: Loss = 1.2644, Accuracy = 0.5795\n",
      "Batch 230: Loss = 1.2625, Accuracy = 0.5804\n",
      "Batch 240: Loss = 1.2696, Accuracy = 0.5789\n",
      "Batch 250: Loss = 1.2713, Accuracy = 0.5788\n",
      "Batch 260: Loss = 1.2689, Accuracy = 0.5803\n",
      "Batch 270: Loss = 1.2684, Accuracy = 0.5807\n",
      "Batch 280: Loss = 1.2689, Accuracy = 0.5805\n",
      "Batch 290: Loss = 1.2720, Accuracy = 0.5782\n",
      "Batch 300: Loss = 1.2746, Accuracy = 0.5787\n",
      "Training - Loss: 1.2717, Accuracy: 0.5807\n",
      "Validation - Loss: 0.8835, Accuracy: 0.7106\n",
      "Epoch 7/30\n",
      "Batch 10: Loss = 1.2209, Accuracy = 0.5469\n",
      "Batch 20: Loss = 1.2030, Accuracy = 0.5672\n",
      "Batch 30: Loss = 1.2172, Accuracy = 0.5719\n",
      "Batch 40: Loss = 1.2127, Accuracy = 0.5820\n",
      "Batch 50: Loss = 1.2552, Accuracy = 0.5713\n",
      "Batch 60: Loss = 1.2316, Accuracy = 0.5828\n",
      "Batch 70: Loss = 1.2260, Accuracy = 0.5826\n",
      "Batch 80: Loss = 1.2202, Accuracy = 0.5840\n",
      "Batch 90: Loss = 1.2185, Accuracy = 0.5847\n",
      "Batch 100: Loss = 1.2296, Accuracy = 0.5803\n",
      "Batch 110: Loss = 1.2346, Accuracy = 0.5767\n",
      "Batch 120: Loss = 1.2328, Accuracy = 0.5779\n",
      "Batch 130: Loss = 1.2293, Accuracy = 0.5817\n",
      "Batch 140: Loss = 1.2372, Accuracy = 0.5790\n",
      "Batch 150: Loss = 1.2437, Accuracy = 0.5769\n",
      "Batch 160: Loss = 1.2403, Accuracy = 0.5787\n",
      "Batch 170: Loss = 1.2380, Accuracy = 0.5789\n",
      "Batch 180: Loss = 1.2372, Accuracy = 0.5806\n",
      "Batch 190: Loss = 1.2379, Accuracy = 0.5804\n",
      "Batch 200: Loss = 1.2385, Accuracy = 0.5805\n",
      "Batch 210: Loss = 1.2331, Accuracy = 0.5824\n",
      "Batch 220: Loss = 1.2372, Accuracy = 0.5824\n",
      "Batch 230: Loss = 1.2359, Accuracy = 0.5819\n",
      "Batch 240: Loss = 1.2327, Accuracy = 0.5818\n",
      "Batch 250: Loss = 1.2363, Accuracy = 0.5809\n",
      "Batch 260: Loss = 1.2353, Accuracy = 0.5813\n",
      "Batch 270: Loss = 1.2335, Accuracy = 0.5816\n",
      "Batch 280: Loss = 1.2384, Accuracy = 0.5800\n",
      "Batch 290: Loss = 1.2387, Accuracy = 0.5807\n",
      "Batch 300: Loss = 1.2402, Accuracy = 0.5808\n",
      "Training - Loss: 1.2389, Accuracy: 0.5821\n",
      "Validation - Loss: 0.9088, Accuracy: 0.7133\n",
      "Epoch 8/30\n",
      "Batch 10: Loss = 1.1133, Accuracy = 0.6156\n",
      "Batch 20: Loss = 1.1278, Accuracy = 0.6203\n",
      "Batch 30: Loss = 1.1243, Accuracy = 0.6083\n",
      "Batch 40: Loss = 1.1699, Accuracy = 0.6055\n",
      "Batch 50: Loss = 1.1604, Accuracy = 0.6100\n",
      "Batch 60: Loss = 1.1786, Accuracy = 0.6010\n",
      "Batch 70: Loss = 1.1741, Accuracy = 0.6009\n",
      "Batch 80: Loss = 1.1702, Accuracy = 0.6023\n",
      "Batch 90: Loss = 1.1696, Accuracy = 0.6059\n",
      "Batch 100: Loss = 1.1760, Accuracy = 0.6034\n",
      "Batch 110: Loss = 1.1875, Accuracy = 0.6037\n",
      "Batch 120: Loss = 1.1830, Accuracy = 0.6039\n",
      "Batch 130: Loss = 1.1831, Accuracy = 0.6031\n",
      "Batch 140: Loss = 1.1849, Accuracy = 0.6036\n",
      "Batch 150: Loss = 1.1924, Accuracy = 0.6021\n",
      "Batch 160: Loss = 1.1957, Accuracy = 0.6016\n",
      "Batch 170: Loss = 1.1910, Accuracy = 0.6015\n",
      "Batch 180: Loss = 1.1877, Accuracy = 0.6030\n",
      "Batch 190: Loss = 1.1887, Accuracy = 0.6023\n",
      "Batch 200: Loss = 1.1961, Accuracy = 0.6006\n",
      "Batch 210: Loss = 1.1944, Accuracy = 0.6004\n",
      "Batch 220: Loss = 1.1933, Accuracy = 0.6030\n",
      "Batch 230: Loss = 1.1988, Accuracy = 0.6008\n",
      "Batch 240: Loss = 1.1993, Accuracy = 0.6003\n",
      "Batch 250: Loss = 1.1980, Accuracy = 0.6003\n",
      "Batch 260: Loss = 1.1965, Accuracy = 0.5996\n",
      "Batch 270: Loss = 1.1965, Accuracy = 0.5997\n",
      "Batch 280: Loss = 1.1989, Accuracy = 0.5993\n",
      "Batch 290: Loss = 1.2006, Accuracy = 0.5989\n",
      "Batch 300: Loss = 1.2012, Accuracy = 0.5990\n",
      "Training - Loss: 1.2016, Accuracy: 0.5984\n",
      "Validation - Loss: 0.8718, Accuracy: 0.7210\n",
      "Epoch 9/30\n",
      "Batch 10: Loss = 1.1888, Accuracy = 0.6000\n",
      "Batch 20: Loss = 1.0768, Accuracy = 0.6516\n",
      "Batch 30: Loss = 1.1420, Accuracy = 0.6354\n",
      "Batch 40: Loss = 1.1577, Accuracy = 0.6289\n",
      "Batch 50: Loss = 1.1466, Accuracy = 0.6338\n",
      "Batch 60: Loss = 1.1571, Accuracy = 0.6281\n",
      "Batch 70: Loss = 1.1524, Accuracy = 0.6281\n",
      "Batch 80: Loss = 1.1557, Accuracy = 0.6227\n",
      "Batch 90: Loss = 1.1633, Accuracy = 0.6198\n",
      "Batch 100: Loss = 1.1601, Accuracy = 0.6181\n",
      "Batch 110: Loss = 1.1548, Accuracy = 0.6187\n",
      "Batch 120: Loss = 1.1636, Accuracy = 0.6174\n",
      "Batch 130: Loss = 1.1641, Accuracy = 0.6185\n",
      "Batch 140: Loss = 1.1725, Accuracy = 0.6165\n",
      "Batch 150: Loss = 1.1756, Accuracy = 0.6150\n",
      "Batch 160: Loss = 1.1771, Accuracy = 0.6143\n",
      "Batch 170: Loss = 1.1713, Accuracy = 0.6162\n",
      "Batch 180: Loss = 1.1768, Accuracy = 0.6151\n",
      "Batch 190: Loss = 1.1774, Accuracy = 0.6153\n",
      "Batch 200: Loss = 1.1756, Accuracy = 0.6158\n",
      "Batch 210: Loss = 1.1808, Accuracy = 0.6132\n",
      "Batch 220: Loss = 1.1797, Accuracy = 0.6146\n",
      "Batch 230: Loss = 1.1767, Accuracy = 0.6154\n",
      "Batch 240: Loss = 1.1789, Accuracy = 0.6155\n",
      "Batch 250: Loss = 1.1783, Accuracy = 0.6155\n",
      "Batch 260: Loss = 1.1731, Accuracy = 0.6156\n",
      "Batch 270: Loss = 1.1786, Accuracy = 0.6142\n",
      "Batch 280: Loss = 1.1784, Accuracy = 0.6144\n",
      "Batch 290: Loss = 1.1749, Accuracy = 0.6153\n",
      "Batch 300: Loss = 1.1787, Accuracy = 0.6144\n",
      "Training - Loss: 1.1738, Accuracy: 0.6158\n",
      "Validation - Loss: 0.8445, Accuracy: 0.7230\n",
      "Epoch 10/30\n",
      "Batch 10: Loss = 1.1819, Accuracy = 0.5906\n",
      "Batch 20: Loss = 1.1843, Accuracy = 0.5859\n",
      "Batch 30: Loss = 1.1707, Accuracy = 0.5917\n",
      "Batch 40: Loss = 1.1528, Accuracy = 0.5977\n",
      "Batch 50: Loss = 1.1755, Accuracy = 0.5900\n",
      "Batch 60: Loss = 1.1636, Accuracy = 0.5943\n",
      "Batch 70: Loss = 1.1489, Accuracy = 0.6031\n",
      "Batch 80: Loss = 1.1575, Accuracy = 0.6023\n",
      "Batch 90: Loss = 1.1523, Accuracy = 0.6038\n",
      "Batch 100: Loss = 1.1521, Accuracy = 0.6044\n",
      "Batch 110: Loss = 1.1456, Accuracy = 0.6054\n",
      "Batch 120: Loss = 1.1453, Accuracy = 0.6065\n",
      "Batch 130: Loss = 1.1438, Accuracy = 0.6087\n",
      "Batch 140: Loss = 1.1397, Accuracy = 0.6100\n",
      "Batch 150: Loss = 1.1347, Accuracy = 0.6131\n",
      "Batch 160: Loss = 1.1268, Accuracy = 0.6145\n",
      "Batch 170: Loss = 1.1286, Accuracy = 0.6164\n",
      "Batch 180: Loss = 1.1324, Accuracy = 0.6158\n",
      "Batch 190: Loss = 1.1413, Accuracy = 0.6133\n",
      "Batch 200: Loss = 1.1422, Accuracy = 0.6131\n",
      "Batch 210: Loss = 1.1408, Accuracy = 0.6124\n",
      "Batch 220: Loss = 1.1420, Accuracy = 0.6122\n",
      "Batch 230: Loss = 1.1441, Accuracy = 0.6118\n",
      "Batch 240: Loss = 1.1480, Accuracy = 0.6105\n",
      "Batch 250: Loss = 1.1487, Accuracy = 0.6111\n",
      "Batch 260: Loss = 1.1466, Accuracy = 0.6112\n",
      "Batch 270: Loss = 1.1439, Accuracy = 0.6109\n",
      "Batch 280: Loss = 1.1453, Accuracy = 0.6104\n",
      "Batch 290: Loss = 1.1461, Accuracy = 0.6111\n",
      "Batch 300: Loss = 1.1450, Accuracy = 0.6125\n",
      "Training - Loss: 1.1429, Accuracy: 0.6127\n",
      "Validation - Loss: 0.8424, Accuracy: 0.7299\n",
      "Epoch 11/30\n",
      "Batch 10: Loss = 1.0922, Accuracy = 0.6406\n",
      "Batch 20: Loss = 1.1127, Accuracy = 0.6313\n",
      "Batch 30: Loss = 1.0903, Accuracy = 0.6333\n",
      "Batch 40: Loss = 1.0669, Accuracy = 0.6523\n",
      "Batch 50: Loss = 1.0857, Accuracy = 0.6388\n",
      "Batch 60: Loss = 1.0943, Accuracy = 0.6380\n",
      "Batch 70: Loss = 1.0964, Accuracy = 0.6429\n",
      "Batch 80: Loss = 1.0948, Accuracy = 0.6418\n",
      "Batch 90: Loss = 1.1010, Accuracy = 0.6368\n",
      "Batch 100: Loss = 1.1061, Accuracy = 0.6334\n",
      "Batch 110: Loss = 1.1201, Accuracy = 0.6324\n",
      "Batch 120: Loss = 1.1140, Accuracy = 0.6331\n",
      "Batch 130: Loss = 1.1203, Accuracy = 0.6305\n",
      "Batch 140: Loss = 1.1200, Accuracy = 0.6281\n",
      "Batch 150: Loss = 1.1173, Accuracy = 0.6279\n",
      "Batch 160: Loss = 1.1177, Accuracy = 0.6293\n",
      "Batch 170: Loss = 1.1171, Accuracy = 0.6301\n",
      "Batch 180: Loss = 1.1120, Accuracy = 0.6318\n",
      "Batch 190: Loss = 1.1104, Accuracy = 0.6326\n",
      "Batch 200: Loss = 1.1101, Accuracy = 0.6331\n",
      "Batch 210: Loss = 1.1133, Accuracy = 0.6326\n",
      "Batch 220: Loss = 1.1149, Accuracy = 0.6322\n",
      "Batch 230: Loss = 1.1175, Accuracy = 0.6317\n",
      "Batch 240: Loss = 1.1182, Accuracy = 0.6297\n",
      "Batch 250: Loss = 1.1157, Accuracy = 0.6292\n",
      "Batch 260: Loss = 1.1177, Accuracy = 0.6297\n",
      "Batch 270: Loss = 1.1171, Accuracy = 0.6303\n",
      "Batch 280: Loss = 1.1149, Accuracy = 0.6310\n",
      "Batch 290: Loss = 1.1092, Accuracy = 0.6335\n",
      "Batch 300: Loss = 1.1124, Accuracy = 0.6329\n",
      "Training - Loss: 1.1132, Accuracy: 0.6324\n",
      "Validation - Loss: 0.8618, Accuracy: 0.7263\n",
      "Epoch 12/30\n",
      "Batch 10: Loss = 1.1395, Accuracy = 0.6625\n",
      "Batch 20: Loss = 1.1150, Accuracy = 0.6500\n",
      "Batch 30: Loss = 1.1083, Accuracy = 0.6385\n",
      "Batch 40: Loss = 1.0971, Accuracy = 0.6445\n",
      "Batch 50: Loss = 1.0946, Accuracy = 0.6463\n",
      "Batch 60: Loss = 1.0944, Accuracy = 0.6453\n",
      "Batch 70: Loss = 1.0766, Accuracy = 0.6464\n",
      "Batch 80: Loss = 1.0892, Accuracy = 0.6398\n",
      "Batch 90: Loss = 1.0974, Accuracy = 0.6354\n",
      "Batch 100: Loss = 1.0897, Accuracy = 0.6394\n",
      "Batch 110: Loss = 1.0982, Accuracy = 0.6330\n",
      "Batch 120: Loss = 1.1006, Accuracy = 0.6336\n",
      "Batch 130: Loss = 1.1100, Accuracy = 0.6310\n",
      "Batch 140: Loss = 1.1118, Accuracy = 0.6313\n",
      "Batch 150: Loss = 1.1136, Accuracy = 0.6308\n",
      "Batch 160: Loss = 1.1158, Accuracy = 0.6273\n",
      "Batch 170: Loss = 1.1134, Accuracy = 0.6279\n",
      "Batch 180: Loss = 1.1097, Accuracy = 0.6278\n",
      "Batch 190: Loss = 1.1109, Accuracy = 0.6271\n",
      "Batch 200: Loss = 1.1070, Accuracy = 0.6284\n",
      "Batch 210: Loss = 1.1110, Accuracy = 0.6289\n",
      "Batch 220: Loss = 1.1121, Accuracy = 0.6291\n",
      "Batch 230: Loss = 1.1086, Accuracy = 0.6295\n",
      "Batch 240: Loss = 1.1119, Accuracy = 0.6288\n",
      "Batch 250: Loss = 1.1124, Accuracy = 0.6294\n",
      "Batch 260: Loss = 1.1134, Accuracy = 0.6299\n",
      "Batch 270: Loss = 1.1116, Accuracy = 0.6294\n",
      "Batch 280: Loss = 1.1102, Accuracy = 0.6300\n",
      "Batch 290: Loss = 1.1109, Accuracy = 0.6302\n",
      "Batch 300: Loss = 1.1083, Accuracy = 0.6310\n",
      "Training - Loss: 1.1062, Accuracy: 0.6316\n",
      "Validation - Loss: 0.8260, Accuracy: 0.7370\n",
      "Epoch 13/30\n",
      "Batch 10: Loss = 1.0695, Accuracy = 0.6344\n",
      "Batch 20: Loss = 1.0692, Accuracy = 0.6359\n",
      "Batch 30: Loss = 1.0644, Accuracy = 0.6510\n",
      "Batch 40: Loss = 1.0729, Accuracy = 0.6430\n",
      "Batch 50: Loss = 1.0915, Accuracy = 0.6363\n",
      "Batch 60: Loss = 1.0953, Accuracy = 0.6344\n",
      "Batch 70: Loss = 1.0866, Accuracy = 0.6344\n",
      "Batch 80: Loss = 1.0815, Accuracy = 0.6328\n",
      "Batch 90: Loss = 1.0914, Accuracy = 0.6257\n",
      "Batch 100: Loss = 1.1063, Accuracy = 0.6209\n",
      "Batch 110: Loss = 1.0997, Accuracy = 0.6241\n",
      "Batch 120: Loss = 1.1008, Accuracy = 0.6250\n",
      "Batch 130: Loss = 1.1043, Accuracy = 0.6248\n",
      "Batch 140: Loss = 1.1089, Accuracy = 0.6214\n",
      "Batch 150: Loss = 1.1049, Accuracy = 0.6237\n",
      "Batch 160: Loss = 1.1103, Accuracy = 0.6242\n",
      "Batch 170: Loss = 1.1096, Accuracy = 0.6270\n",
      "Batch 180: Loss = 1.1076, Accuracy = 0.6267\n",
      "Batch 190: Loss = 1.1045, Accuracy = 0.6276\n",
      "Batch 200: Loss = 1.1049, Accuracy = 0.6277\n",
      "Batch 210: Loss = 1.1023, Accuracy = 0.6286\n",
      "Batch 220: Loss = 1.1027, Accuracy = 0.6301\n",
      "Batch 230: Loss = 1.1037, Accuracy = 0.6300\n",
      "Batch 240: Loss = 1.1025, Accuracy = 0.6303\n",
      "Batch 250: Loss = 1.1027, Accuracy = 0.6301\n",
      "Batch 260: Loss = 1.1058, Accuracy = 0.6281\n",
      "Batch 270: Loss = 1.1080, Accuracy = 0.6275\n",
      "Batch 280: Loss = 1.1095, Accuracy = 0.6277\n",
      "Batch 290: Loss = 1.1099, Accuracy = 0.6279\n",
      "Batch 300: Loss = 1.1083, Accuracy = 0.6280\n",
      "Training - Loss: 1.1092, Accuracy: 0.6271\n",
      "Validation - Loss: 0.7948, Accuracy: 0.7487\n",
      "Epoch 14/30\n",
      "Batch 10: Loss = 1.0197, Accuracy = 0.6875\n",
      "Batch 20: Loss = 1.0502, Accuracy = 0.6750\n",
      "Batch 30: Loss = 1.0500, Accuracy = 0.6698\n",
      "Batch 40: Loss = 1.0374, Accuracy = 0.6680\n",
      "Batch 50: Loss = 1.0574, Accuracy = 0.6569\n",
      "Batch 60: Loss = 1.0560, Accuracy = 0.6557\n",
      "Batch 70: Loss = 1.0480, Accuracy = 0.6567\n",
      "Batch 80: Loss = 1.0603, Accuracy = 0.6512\n",
      "Batch 90: Loss = 1.0630, Accuracy = 0.6490\n",
      "Batch 100: Loss = 1.0668, Accuracy = 0.6475\n",
      "Batch 110: Loss = 1.0655, Accuracy = 0.6480\n",
      "Batch 120: Loss = 1.0683, Accuracy = 0.6469\n",
      "Batch 130: Loss = 1.0699, Accuracy = 0.6435\n",
      "Batch 140: Loss = 1.0683, Accuracy = 0.6431\n",
      "Batch 150: Loss = 1.0684, Accuracy = 0.6415\n",
      "Batch 160: Loss = 1.0733, Accuracy = 0.6416\n",
      "Batch 170: Loss = 1.0822, Accuracy = 0.6388\n",
      "Batch 180: Loss = 1.0800, Accuracy = 0.6389\n",
      "Batch 190: Loss = 1.0856, Accuracy = 0.6378\n",
      "Batch 200: Loss = 1.0900, Accuracy = 0.6356\n",
      "Batch 210: Loss = 1.0861, Accuracy = 0.6359\n",
      "Batch 220: Loss = 1.0870, Accuracy = 0.6364\n",
      "Batch 230: Loss = 1.0837, Accuracy = 0.6368\n",
      "Batch 240: Loss = 1.0782, Accuracy = 0.6374\n",
      "Batch 250: Loss = 1.0777, Accuracy = 0.6378\n",
      "Batch 260: Loss = 1.0750, Accuracy = 0.6391\n",
      "Batch 270: Loss = 1.0697, Accuracy = 0.6414\n",
      "Batch 280: Loss = 1.0701, Accuracy = 0.6423\n",
      "Batch 290: Loss = 1.0737, Accuracy = 0.6407\n",
      "Batch 300: Loss = 1.0705, Accuracy = 0.6413\n",
      "Training - Loss: 1.0694, Accuracy: 0.6414\n",
      "Validation - Loss: 0.7864, Accuracy: 0.7526\n",
      "Epoch 15/30\n",
      "Batch 10: Loss = 1.0987, Accuracy = 0.6000\n",
      "Batch 20: Loss = 1.1135, Accuracy = 0.6062\n",
      "Batch 30: Loss = 1.0671, Accuracy = 0.6208\n",
      "Batch 40: Loss = 1.0896, Accuracy = 0.6211\n",
      "Batch 50: Loss = 1.0821, Accuracy = 0.6244\n",
      "Batch 60: Loss = 1.0789, Accuracy = 0.6271\n",
      "Batch 70: Loss = 1.0632, Accuracy = 0.6326\n",
      "Batch 80: Loss = 1.0661, Accuracy = 0.6332\n",
      "Batch 90: Loss = 1.0663, Accuracy = 0.6333\n",
      "Batch 100: Loss = 1.0655, Accuracy = 0.6375\n",
      "Batch 110: Loss = 1.0547, Accuracy = 0.6372\n",
      "Batch 120: Loss = 1.0580, Accuracy = 0.6393\n",
      "Batch 130: Loss = 1.0494, Accuracy = 0.6399\n",
      "Batch 140: Loss = 1.0442, Accuracy = 0.6431\n",
      "Batch 150: Loss = 1.0428, Accuracy = 0.6444\n",
      "Batch 160: Loss = 1.0422, Accuracy = 0.6426\n",
      "Batch 170: Loss = 1.0463, Accuracy = 0.6426\n",
      "Batch 180: Loss = 1.0539, Accuracy = 0.6405\n",
      "Batch 190: Loss = 1.0546, Accuracy = 0.6414\n",
      "Batch 200: Loss = 1.0515, Accuracy = 0.6436\n",
      "Batch 210: Loss = 1.0508, Accuracy = 0.6429\n",
      "Batch 220: Loss = 1.0569, Accuracy = 0.6399\n",
      "Batch 230: Loss = 1.0521, Accuracy = 0.6416\n",
      "Batch 240: Loss = 1.0537, Accuracy = 0.6427\n",
      "Batch 250: Loss = 1.0516, Accuracy = 0.6439\n",
      "Batch 260: Loss = 1.0558, Accuracy = 0.6436\n",
      "Batch 270: Loss = 1.0568, Accuracy = 0.6436\n",
      "Batch 280: Loss = 1.0612, Accuracy = 0.6432\n",
      "Batch 290: Loss = 1.0549, Accuracy = 0.6461\n",
      "Batch 300: Loss = 1.0589, Accuracy = 0.6445\n",
      "Training - Loss: 1.0552, Accuracy: 0.6462\n",
      "Validation - Loss: 0.8092, Accuracy: 0.7415\n",
      "Epoch 16/30\n",
      "Batch 10: Loss = 1.0619, Accuracy = 0.6219\n",
      "Batch 20: Loss = 1.0077, Accuracy = 0.6609\n",
      "Batch 30: Loss = 1.0145, Accuracy = 0.6604\n",
      "Batch 40: Loss = 1.0152, Accuracy = 0.6648\n",
      "Batch 50: Loss = 1.0276, Accuracy = 0.6581\n",
      "Batch 60: Loss = 1.0246, Accuracy = 0.6599\n",
      "Batch 70: Loss = 1.0432, Accuracy = 0.6554\n",
      "Batch 80: Loss = 1.0422, Accuracy = 0.6566\n",
      "Batch 90: Loss = 1.0590, Accuracy = 0.6486\n",
      "Batch 100: Loss = 1.0477, Accuracy = 0.6531\n",
      "Batch 110: Loss = 1.0425, Accuracy = 0.6557\n",
      "Batch 120: Loss = 1.0391, Accuracy = 0.6583\n",
      "Batch 130: Loss = 1.0382, Accuracy = 0.6594\n",
      "Batch 140: Loss = 1.0386, Accuracy = 0.6600\n",
      "Batch 150: Loss = 1.0350, Accuracy = 0.6621\n",
      "Batch 160: Loss = 1.0343, Accuracy = 0.6605\n",
      "Batch 170: Loss = 1.0367, Accuracy = 0.6603\n",
      "Batch 180: Loss = 1.0389, Accuracy = 0.6582\n",
      "Batch 190: Loss = 1.0406, Accuracy = 0.6574\n",
      "Batch 200: Loss = 1.0408, Accuracy = 0.6580\n",
      "Batch 210: Loss = 1.0416, Accuracy = 0.6585\n",
      "Batch 220: Loss = 1.0448, Accuracy = 0.6585\n",
      "Batch 230: Loss = 1.0468, Accuracy = 0.6576\n",
      "Batch 240: Loss = 1.0434, Accuracy = 0.6589\n",
      "Batch 250: Loss = 1.0468, Accuracy = 0.6584\n",
      "Batch 260: Loss = 1.0505, Accuracy = 0.6564\n",
      "Batch 270: Loss = 1.0483, Accuracy = 0.6566\n",
      "Batch 280: Loss = 1.0458, Accuracy = 0.6572\n",
      "Batch 290: Loss = 1.0471, Accuracy = 0.6564\n",
      "Batch 300: Loss = 1.0451, Accuracy = 0.6554\n",
      "Training - Loss: 1.0479, Accuracy: 0.6541\n",
      "Validation - Loss: 0.8710, Accuracy: 0.7242\n",
      "Epoch 17/30\n",
      "Batch 10: Loss = 1.1092, Accuracy = 0.6094\n",
      "Batch 20: Loss = 1.1367, Accuracy = 0.6172\n",
      "Batch 30: Loss = 1.0676, Accuracy = 0.6375\n",
      "Batch 40: Loss = 1.0711, Accuracy = 0.6383\n",
      "Batch 50: Loss = 1.0650, Accuracy = 0.6350\n",
      "Batch 60: Loss = 1.0609, Accuracy = 0.6380\n",
      "Batch 70: Loss = 1.0633, Accuracy = 0.6402\n",
      "Batch 80: Loss = 1.0645, Accuracy = 0.6418\n",
      "Batch 90: Loss = 1.0602, Accuracy = 0.6444\n",
      "Batch 100: Loss = 1.0517, Accuracy = 0.6475\n",
      "Batch 110: Loss = 1.0387, Accuracy = 0.6526\n",
      "Batch 120: Loss = 1.0383, Accuracy = 0.6544\n",
      "Batch 130: Loss = 1.0423, Accuracy = 0.6534\n",
      "Batch 140: Loss = 1.0381, Accuracy = 0.6558\n",
      "Batch 150: Loss = 1.0424, Accuracy = 0.6540\n",
      "Batch 160: Loss = 1.0406, Accuracy = 0.6566\n",
      "Batch 170: Loss = 1.0395, Accuracy = 0.6586\n",
      "Batch 180: Loss = 1.0418, Accuracy = 0.6573\n",
      "Batch 190: Loss = 1.0441, Accuracy = 0.6571\n",
      "Batch 200: Loss = 1.0412, Accuracy = 0.6577\n",
      "Batch 210: Loss = 1.0426, Accuracy = 0.6562\n",
      "Batch 220: Loss = 1.0398, Accuracy = 0.6562\n",
      "Batch 230: Loss = 1.0381, Accuracy = 0.6564\n",
      "Batch 240: Loss = 1.0345, Accuracy = 0.6578\n",
      "Batch 250: Loss = 1.0329, Accuracy = 0.6581\n",
      "Batch 260: Loss = 1.0323, Accuracy = 0.6593\n",
      "Batch 270: Loss = 1.0370, Accuracy = 0.6576\n",
      "Batch 280: Loss = 1.0369, Accuracy = 0.6577\n",
      "Batch 290: Loss = 1.0341, Accuracy = 0.6582\n",
      "Batch 300: Loss = 1.0335, Accuracy = 0.6576\n",
      "Training - Loss: 1.0317, Accuracy: 0.6584\n",
      "Validation - Loss: 0.7913, Accuracy: 0.7554\n",
      "Epoch 18/30\n",
      "Batch 10: Loss = 0.9866, Accuracy = 0.6906\n",
      "Batch 20: Loss = 0.9952, Accuracy = 0.6734\n",
      "Batch 30: Loss = 1.0062, Accuracy = 0.6698\n",
      "Batch 40: Loss = 1.0091, Accuracy = 0.6664\n",
      "Batch 50: Loss = 1.0191, Accuracy = 0.6606\n",
      "Batch 60: Loss = 1.0285, Accuracy = 0.6562\n",
      "Batch 70: Loss = 1.0113, Accuracy = 0.6571\n",
      "Batch 80: Loss = 1.0250, Accuracy = 0.6527\n",
      "Batch 90: Loss = 1.0352, Accuracy = 0.6503\n",
      "Batch 100: Loss = 1.0314, Accuracy = 0.6513\n",
      "Batch 110: Loss = 1.0358, Accuracy = 0.6540\n",
      "Batch 120: Loss = 1.0330, Accuracy = 0.6573\n",
      "Batch 130: Loss = 1.0316, Accuracy = 0.6584\n",
      "Batch 140: Loss = 1.0351, Accuracy = 0.6589\n",
      "Batch 150: Loss = 1.0280, Accuracy = 0.6600\n",
      "Batch 160: Loss = 1.0291, Accuracy = 0.6582\n",
      "Batch 170: Loss = 1.0308, Accuracy = 0.6561\n",
      "Batch 180: Loss = 1.0265, Accuracy = 0.6576\n",
      "Batch 190: Loss = 1.0350, Accuracy = 0.6536\n",
      "Batch 200: Loss = 1.0396, Accuracy = 0.6511\n",
      "Batch 210: Loss = 1.0372, Accuracy = 0.6518\n",
      "Batch 220: Loss = 1.0408, Accuracy = 0.6513\n",
      "Batch 230: Loss = 1.0439, Accuracy = 0.6518\n",
      "Batch 240: Loss = 1.0432, Accuracy = 0.6518\n",
      "Batch 250: Loss = 1.0475, Accuracy = 0.6494\n",
      "Batch 260: Loss = 1.0477, Accuracy = 0.6502\n",
      "Batch 270: Loss = 1.0465, Accuracy = 0.6509\n",
      "Batch 280: Loss = 1.0428, Accuracy = 0.6528\n",
      "Batch 290: Loss = 1.0482, Accuracy = 0.6514\n",
      "Batch 300: Loss = 1.0453, Accuracy = 0.6523\n",
      "Training - Loss: 1.0421, Accuracy: 0.6533\n",
      "Validation - Loss: 0.8001, Accuracy: 0.7408\n",
      "Epoch 19/30\n",
      "Batch 10: Loss = 0.9916, Accuracy = 0.6469\n",
      "Batch 20: Loss = 1.0764, Accuracy = 0.6391\n",
      "Batch 30: Loss = 1.0983, Accuracy = 0.6375\n",
      "Batch 40: Loss = 1.0821, Accuracy = 0.6422\n",
      "Batch 50: Loss = 1.0788, Accuracy = 0.6394\n",
      "Batch 60: Loss = 1.0645, Accuracy = 0.6422\n",
      "Batch 70: Loss = 1.0582, Accuracy = 0.6478\n",
      "Batch 80: Loss = 1.0548, Accuracy = 0.6504\n",
      "Batch 90: Loss = 1.0397, Accuracy = 0.6562\n",
      "Batch 100: Loss = 1.0411, Accuracy = 0.6575\n",
      "Batch 110: Loss = 1.0509, Accuracy = 0.6565\n",
      "Batch 120: Loss = 1.0416, Accuracy = 0.6612\n",
      "Batch 130: Loss = 1.0425, Accuracy = 0.6579\n",
      "Batch 140: Loss = 1.0407, Accuracy = 0.6589\n",
      "Batch 150: Loss = 1.0387, Accuracy = 0.6583\n",
      "Batch 160: Loss = 1.0370, Accuracy = 0.6594\n",
      "Batch 170: Loss = 1.0431, Accuracy = 0.6581\n",
      "Batch 180: Loss = 1.0378, Accuracy = 0.6590\n",
      "Batch 190: Loss = 1.0319, Accuracy = 0.6605\n",
      "Batch 200: Loss = 1.0297, Accuracy = 0.6597\n",
      "Batch 210: Loss = 1.0307, Accuracy = 0.6592\n",
      "Batch 220: Loss = 1.0284, Accuracy = 0.6611\n",
      "Batch 230: Loss = 1.0332, Accuracy = 0.6591\n",
      "Batch 240: Loss = 1.0306, Accuracy = 0.6594\n",
      "Batch 250: Loss = 1.0276, Accuracy = 0.6604\n",
      "Batch 260: Loss = 1.0326, Accuracy = 0.6599\n",
      "Batch 270: Loss = 1.0300, Accuracy = 0.6608\n",
      "Batch 280: Loss = 1.0314, Accuracy = 0.6599\n",
      "Batch 290: Loss = 1.0312, Accuracy = 0.6611\n",
      "Batch 300: Loss = 1.0292, Accuracy = 0.6612\n",
      "Training - Loss: 1.0300, Accuracy: 0.6602\n",
      "Validation - Loss: 0.8171, Accuracy: 0.7435\n",
      "Epoch 20/30\n",
      "Batch 10: Loss = 1.0808, Accuracy = 0.6406\n",
      "Batch 20: Loss = 1.0462, Accuracy = 0.6547\n",
      "Batch 30: Loss = 1.0468, Accuracy = 0.6500\n",
      "Batch 40: Loss = 1.0418, Accuracy = 0.6523\n",
      "Batch 50: Loss = 1.0139, Accuracy = 0.6606\n",
      "Batch 60: Loss = 1.0208, Accuracy = 0.6557\n",
      "Batch 70: Loss = 1.0121, Accuracy = 0.6594\n",
      "Batch 80: Loss = 0.9963, Accuracy = 0.6652\n",
      "Batch 90: Loss = 1.0152, Accuracy = 0.6615\n",
      "Batch 100: Loss = 1.0205, Accuracy = 0.6600\n",
      "Batch 110: Loss = 1.0169, Accuracy = 0.6611\n",
      "Batch 120: Loss = 1.0173, Accuracy = 0.6607\n",
      "Batch 130: Loss = 1.0249, Accuracy = 0.6582\n",
      "Batch 140: Loss = 1.0252, Accuracy = 0.6576\n",
      "Batch 150: Loss = 1.0237, Accuracy = 0.6610\n",
      "Batch 160: Loss = 1.0263, Accuracy = 0.6594\n",
      "Batch 170: Loss = 1.0265, Accuracy = 0.6605\n",
      "Batch 180: Loss = 1.0272, Accuracy = 0.6590\n",
      "Batch 190: Loss = 1.0262, Accuracy = 0.6615\n",
      "Batch 200: Loss = 1.0211, Accuracy = 0.6630\n",
      "Batch 210: Loss = 1.0239, Accuracy = 0.6625\n",
      "Batch 220: Loss = 1.0206, Accuracy = 0.6639\n",
      "Batch 230: Loss = 1.0166, Accuracy = 0.6644\n",
      "Batch 240: Loss = 1.0179, Accuracy = 0.6645\n",
      "Batch 250: Loss = 1.0217, Accuracy = 0.6633\n",
      "Batch 260: Loss = 1.0252, Accuracy = 0.6615\n",
      "Batch 270: Loss = 1.0302, Accuracy = 0.6605\n",
      "Batch 280: Loss = 1.0268, Accuracy = 0.6603\n",
      "Batch 290: Loss = 1.0200, Accuracy = 0.6627\n",
      "Batch 300: Loss = 1.0213, Accuracy = 0.6615\n",
      "Training - Loss: 1.0188, Accuracy: 0.6633\n",
      "Validation - Loss: 0.7830, Accuracy: 0.7568\n",
      "Epoch 21/30\n",
      "Batch 10: Loss = 0.9191, Accuracy = 0.6969\n",
      "Batch 20: Loss = 1.0440, Accuracy = 0.6766\n",
      "Batch 30: Loss = 1.0025, Accuracy = 0.6750\n",
      "Batch 40: Loss = 0.9847, Accuracy = 0.6820\n",
      "Batch 50: Loss = 1.0005, Accuracy = 0.6800\n",
      "Batch 60: Loss = 1.0157, Accuracy = 0.6781\n",
      "Batch 70: Loss = 1.0246, Accuracy = 0.6723\n",
      "Batch 80: Loss = 1.0436, Accuracy = 0.6625\n",
      "Batch 90: Loss = 1.0450, Accuracy = 0.6622\n",
      "Batch 100: Loss = 1.0484, Accuracy = 0.6597\n",
      "Batch 110: Loss = 1.0406, Accuracy = 0.6625\n",
      "Batch 120: Loss = 1.0350, Accuracy = 0.6630\n",
      "Batch 130: Loss = 1.0404, Accuracy = 0.6618\n",
      "Batch 140: Loss = 1.0317, Accuracy = 0.6647\n",
      "Batch 150: Loss = 1.0317, Accuracy = 0.6635\n",
      "Batch 160: Loss = 1.0281, Accuracy = 0.6650\n",
      "Batch 170: Loss = 1.0327, Accuracy = 0.6640\n",
      "Batch 180: Loss = 1.0333, Accuracy = 0.6623\n",
      "Batch 190: Loss = 1.0273, Accuracy = 0.6638\n",
      "Batch 200: Loss = 1.0265, Accuracy = 0.6644\n",
      "Batch 210: Loss = 1.0244, Accuracy = 0.6650\n",
      "Batch 220: Loss = 1.0233, Accuracy = 0.6642\n",
      "Batch 230: Loss = 1.0242, Accuracy = 0.6656\n",
      "Batch 240: Loss = 1.0258, Accuracy = 0.6658\n",
      "Batch 250: Loss = 1.0257, Accuracy = 0.6647\n",
      "Batch 260: Loss = 1.0254, Accuracy = 0.6647\n",
      "Batch 270: Loss = 1.0209, Accuracy = 0.6659\n",
      "Batch 280: Loss = 1.0178, Accuracy = 0.6667\n",
      "Batch 290: Loss = 1.0152, Accuracy = 0.6674\n",
      "Batch 300: Loss = 1.0118, Accuracy = 0.6688\n",
      "Training - Loss: 1.0117, Accuracy: 0.6680\n",
      "Validation - Loss: 0.7690, Accuracy: 0.7547\n",
      "Epoch 22/30\n",
      "Batch 10: Loss = 0.9391, Accuracy = 0.7094\n",
      "Batch 20: Loss = 0.9304, Accuracy = 0.6906\n",
      "Batch 30: Loss = 0.9237, Accuracy = 0.6875\n",
      "Batch 40: Loss = 0.9730, Accuracy = 0.6773\n",
      "Batch 50: Loss = 0.9868, Accuracy = 0.6731\n",
      "Batch 60: Loss = 0.9812, Accuracy = 0.6755\n",
      "Batch 70: Loss = 0.9778, Accuracy = 0.6737\n",
      "Batch 80: Loss = 0.9836, Accuracy = 0.6762\n",
      "Batch 90: Loss = 0.9923, Accuracy = 0.6743\n",
      "Batch 100: Loss = 0.9916, Accuracy = 0.6750\n",
      "Batch 110: Loss = 0.9930, Accuracy = 0.6739\n",
      "Batch 120: Loss = 0.9921, Accuracy = 0.6732\n",
      "Batch 130: Loss = 0.9935, Accuracy = 0.6738\n",
      "Batch 140: Loss = 0.9918, Accuracy = 0.6748\n",
      "Batch 150: Loss = 0.9922, Accuracy = 0.6727\n",
      "Batch 160: Loss = 1.0065, Accuracy = 0.6687\n",
      "Batch 170: Loss = 1.0051, Accuracy = 0.6684\n",
      "Batch 180: Loss = 1.0014, Accuracy = 0.6693\n",
      "Batch 190: Loss = 1.0040, Accuracy = 0.6692\n",
      "Batch 200: Loss = 1.0054, Accuracy = 0.6678\n",
      "Batch 210: Loss = 1.0008, Accuracy = 0.6696\n",
      "Batch 220: Loss = 1.0040, Accuracy = 0.6673\n",
      "Batch 230: Loss = 1.0007, Accuracy = 0.6687\n",
      "Batch 240: Loss = 1.0019, Accuracy = 0.6673\n",
      "Batch 250: Loss = 1.0004, Accuracy = 0.6664\n",
      "Batch 260: Loss = 1.0003, Accuracy = 0.6659\n",
      "Batch 270: Loss = 0.9980, Accuracy = 0.6666\n",
      "Batch 280: Loss = 0.9943, Accuracy = 0.6674\n",
      "Batch 290: Loss = 0.9956, Accuracy = 0.6674\n",
      "Batch 300: Loss = 0.9903, Accuracy = 0.6696\n",
      "Training - Loss: 0.9901, Accuracy: 0.6699\n",
      "Validation - Loss: 0.7819, Accuracy: 0.7588\n",
      "Epoch 23/30\n",
      "Batch 10: Loss = 1.0148, Accuracy = 0.6750\n",
      "Batch 20: Loss = 0.9850, Accuracy = 0.6875\n",
      "Batch 30: Loss = 0.9463, Accuracy = 0.6917\n",
      "Batch 40: Loss = 0.9527, Accuracy = 0.6906\n",
      "Batch 50: Loss = 0.9648, Accuracy = 0.6869\n",
      "Batch 60: Loss = 0.9461, Accuracy = 0.6953\n",
      "Batch 70: Loss = 0.9619, Accuracy = 0.6897\n",
      "Batch 80: Loss = 0.9578, Accuracy = 0.6883\n",
      "Batch 90: Loss = 0.9556, Accuracy = 0.6854\n",
      "Batch 100: Loss = 0.9666, Accuracy = 0.6819\n",
      "Batch 110: Loss = 0.9628, Accuracy = 0.6801\n",
      "Batch 120: Loss = 0.9762, Accuracy = 0.6766\n",
      "Batch 130: Loss = 0.9765, Accuracy = 0.6774\n",
      "Batch 140: Loss = 0.9790, Accuracy = 0.6772\n",
      "Batch 150: Loss = 0.9884, Accuracy = 0.6760\n",
      "Batch 160: Loss = 0.9989, Accuracy = 0.6729\n",
      "Batch 170: Loss = 0.9989, Accuracy = 0.6737\n",
      "Batch 180: Loss = 0.9986, Accuracy = 0.6720\n",
      "Batch 190: Loss = 0.9935, Accuracy = 0.6737\n",
      "Batch 200: Loss = 0.9974, Accuracy = 0.6722\n",
      "Batch 210: Loss = 1.0056, Accuracy = 0.6698\n",
      "Batch 220: Loss = 1.0035, Accuracy = 0.6707\n",
      "Batch 230: Loss = 1.0108, Accuracy = 0.6692\n",
      "Batch 240: Loss = 1.0130, Accuracy = 0.6676\n",
      "Batch 250: Loss = 1.0098, Accuracy = 0.6672\n",
      "Batch 260: Loss = 1.0098, Accuracy = 0.6673\n",
      "Batch 270: Loss = 1.0093, Accuracy = 0.6677\n",
      "Batch 280: Loss = 1.0074, Accuracy = 0.6679\n",
      "Batch 290: Loss = 1.0064, Accuracy = 0.6688\n",
      "Batch 300: Loss = 1.0026, Accuracy = 0.6704\n",
      "Training - Loss: 1.0016, Accuracy: 0.6709\n",
      "Validation - Loss: 0.7431, Accuracy: 0.7666\n",
      "Epoch 24/30\n",
      "Batch 10: Loss = 0.9379, Accuracy = 0.6469\n",
      "Batch 20: Loss = 0.9347, Accuracy = 0.6672\n",
      "Batch 30: Loss = 0.9258, Accuracy = 0.6687\n",
      "Batch 40: Loss = 0.9365, Accuracy = 0.6695\n",
      "Batch 50: Loss = 0.9565, Accuracy = 0.6650\n",
      "Batch 60: Loss = 0.9688, Accuracy = 0.6615\n",
      "Batch 70: Loss = 0.9770, Accuracy = 0.6616\n",
      "Batch 80: Loss = 0.9687, Accuracy = 0.6727\n",
      "Batch 90: Loss = 0.9648, Accuracy = 0.6750\n",
      "Batch 100: Loss = 0.9637, Accuracy = 0.6753\n",
      "Batch 110: Loss = 0.9609, Accuracy = 0.6776\n",
      "Batch 120: Loss = 0.9788, Accuracy = 0.6706\n",
      "Batch 130: Loss = 0.9772, Accuracy = 0.6695\n",
      "Batch 140: Loss = 0.9793, Accuracy = 0.6701\n",
      "Batch 150: Loss = 0.9822, Accuracy = 0.6698\n",
      "Batch 160: Loss = 0.9803, Accuracy = 0.6711\n",
      "Batch 170: Loss = 0.9746, Accuracy = 0.6722\n",
      "Batch 180: Loss = 0.9699, Accuracy = 0.6740\n",
      "Batch 190: Loss = 0.9703, Accuracy = 0.6747\n",
      "Batch 200: Loss = 0.9717, Accuracy = 0.6737\n",
      "Batch 210: Loss = 0.9708, Accuracy = 0.6749\n",
      "Batch 220: Loss = 0.9727, Accuracy = 0.6746\n",
      "Batch 230: Loss = 0.9795, Accuracy = 0.6723\n",
      "Batch 240: Loss = 0.9762, Accuracy = 0.6738\n",
      "Batch 250: Loss = 0.9778, Accuracy = 0.6736\n",
      "Batch 260: Loss = 0.9796, Accuracy = 0.6744\n",
      "Batch 270: Loss = 0.9807, Accuracy = 0.6743\n",
      "Batch 280: Loss = 0.9778, Accuracy = 0.6762\n",
      "Batch 290: Loss = 0.9772, Accuracy = 0.6760\n",
      "Batch 300: Loss = 0.9754, Accuracy = 0.6760\n",
      "Training - Loss: 0.9766, Accuracy: 0.6765\n",
      "Validation - Loss: 0.7725, Accuracy: 0.7717\n",
      "Epoch 25/30\n",
      "Batch 10: Loss = 1.0727, Accuracy = 0.6219\n",
      "Batch 20: Loss = 1.0643, Accuracy = 0.6391\n",
      "Batch 30: Loss = 1.0316, Accuracy = 0.6479\n",
      "Batch 40: Loss = 1.0296, Accuracy = 0.6500\n",
      "Batch 50: Loss = 1.0394, Accuracy = 0.6519\n",
      "Batch 60: Loss = 1.0509, Accuracy = 0.6521\n",
      "Batch 70: Loss = 1.0601, Accuracy = 0.6464\n",
      "Batch 80: Loss = 1.0718, Accuracy = 0.6430\n",
      "Batch 90: Loss = 1.0464, Accuracy = 0.6531\n",
      "Batch 100: Loss = 1.0446, Accuracy = 0.6525\n",
      "Batch 110: Loss = 1.0334, Accuracy = 0.6568\n",
      "Batch 120: Loss = 1.0249, Accuracy = 0.6591\n",
      "Batch 130: Loss = 1.0174, Accuracy = 0.6613\n",
      "Batch 140: Loss = 1.0126, Accuracy = 0.6618\n",
      "Batch 150: Loss = 1.0037, Accuracy = 0.6662\n",
      "Batch 160: Loss = 0.9994, Accuracy = 0.6680\n",
      "Batch 170: Loss = 1.0017, Accuracy = 0.6667\n",
      "Batch 180: Loss = 1.0045, Accuracy = 0.6672\n",
      "Batch 190: Loss = 1.0057, Accuracy = 0.6658\n",
      "Batch 200: Loss = 1.0090, Accuracy = 0.6644\n",
      "Batch 210: Loss = 1.0033, Accuracy = 0.6661\n",
      "Batch 220: Loss = 1.0030, Accuracy = 0.6683\n",
      "Batch 230: Loss = 1.0067, Accuracy = 0.6674\n",
      "Batch 240: Loss = 1.0105, Accuracy = 0.6661\n",
      "Batch 250: Loss = 1.0100, Accuracy = 0.6656\n",
      "Batch 260: Loss = 1.0142, Accuracy = 0.6648\n",
      "Batch 270: Loss = 1.0144, Accuracy = 0.6652\n",
      "Batch 280: Loss = 1.0149, Accuracy = 0.6646\n",
      "Batch 290: Loss = 1.0151, Accuracy = 0.6639\n",
      "Batch 300: Loss = 1.0158, Accuracy = 0.6640\n",
      "Training - Loss: 1.0097, Accuracy: 0.6665\n",
      "Validation - Loss: 0.7518, Accuracy: 0.7656\n",
      "Epoch 26/30\n",
      "Batch 10: Loss = 0.9692, Accuracy = 0.7031\n",
      "Batch 20: Loss = 0.9957, Accuracy = 0.6766\n",
      "Batch 30: Loss = 1.0241, Accuracy = 0.6552\n",
      "Batch 40: Loss = 1.0336, Accuracy = 0.6570\n",
      "Batch 50: Loss = 1.0021, Accuracy = 0.6662\n",
      "Batch 60: Loss = 1.0048, Accuracy = 0.6646\n",
      "Batch 70: Loss = 0.9902, Accuracy = 0.6683\n",
      "Batch 80: Loss = 0.9971, Accuracy = 0.6664\n",
      "Batch 90: Loss = 0.9906, Accuracy = 0.6705\n",
      "Batch 100: Loss = 0.9868, Accuracy = 0.6737\n",
      "Batch 110: Loss = 0.9758, Accuracy = 0.6801\n",
      "Batch 120: Loss = 0.9723, Accuracy = 0.6823\n",
      "Batch 130: Loss = 0.9738, Accuracy = 0.6812\n",
      "Batch 140: Loss = 0.9791, Accuracy = 0.6795\n",
      "Batch 150: Loss = 0.9763, Accuracy = 0.6812\n",
      "Batch 160: Loss = 0.9749, Accuracy = 0.6781\n",
      "Batch 170: Loss = 0.9689, Accuracy = 0.6801\n",
      "Batch 180: Loss = 0.9685, Accuracy = 0.6786\n",
      "Batch 190: Loss = 0.9694, Accuracy = 0.6780\n",
      "Batch 200: Loss = 0.9758, Accuracy = 0.6778\n",
      "Batch 210: Loss = 0.9772, Accuracy = 0.6781\n",
      "Batch 220: Loss = 0.9766, Accuracy = 0.6790\n",
      "Batch 230: Loss = 0.9746, Accuracy = 0.6807\n",
      "Batch 240: Loss = 0.9724, Accuracy = 0.6805\n",
      "Batch 250: Loss = 0.9690, Accuracy = 0.6817\n",
      "Batch 260: Loss = 0.9657, Accuracy = 0.6824\n",
      "Batch 270: Loss = 0.9667, Accuracy = 0.6824\n",
      "Batch 280: Loss = 0.9671, Accuracy = 0.6825\n",
      "Batch 290: Loss = 0.9673, Accuracy = 0.6826\n",
      "Batch 300: Loss = 0.9657, Accuracy = 0.6828\n",
      "Training - Loss: 0.9700, Accuracy: 0.6815\n",
      "Validation - Loss: 0.8106, Accuracy: 0.7491\n",
      "Epoch 27/30\n",
      "Batch 10: Loss = 1.0360, Accuracy = 0.6438\n",
      "Batch 20: Loss = 0.9673, Accuracy = 0.6719\n",
      "Batch 30: Loss = 0.9723, Accuracy = 0.6677\n",
      "Batch 40: Loss = 0.9609, Accuracy = 0.6695\n",
      "Batch 50: Loss = 0.9811, Accuracy = 0.6625\n",
      "Batch 60: Loss = 0.9776, Accuracy = 0.6641\n",
      "Batch 70: Loss = 0.9864, Accuracy = 0.6670\n",
      "Batch 80: Loss = 0.9742, Accuracy = 0.6734\n",
      "Batch 90: Loss = 0.9667, Accuracy = 0.6771\n",
      "Batch 100: Loss = 0.9702, Accuracy = 0.6766\n",
      "Batch 110: Loss = 0.9744, Accuracy = 0.6761\n",
      "Batch 120: Loss = 0.9806, Accuracy = 0.6753\n",
      "Batch 130: Loss = 0.9764, Accuracy = 0.6781\n",
      "Batch 140: Loss = 0.9817, Accuracy = 0.6766\n",
      "Batch 150: Loss = 0.9853, Accuracy = 0.6752\n",
      "Batch 160: Loss = 0.9834, Accuracy = 0.6754\n",
      "Batch 170: Loss = 0.9853, Accuracy = 0.6767\n",
      "Batch 180: Loss = 0.9812, Accuracy = 0.6783\n",
      "Batch 190: Loss = 0.9814, Accuracy = 0.6776\n",
      "Batch 200: Loss = 0.9832, Accuracy = 0.6748\n",
      "Batch 210: Loss = 0.9812, Accuracy = 0.6757\n",
      "Batch 220: Loss = 0.9832, Accuracy = 0.6746\n",
      "Batch 230: Loss = 0.9750, Accuracy = 0.6772\n",
      "Batch 240: Loss = 0.9695, Accuracy = 0.6801\n",
      "Batch 250: Loss = 0.9682, Accuracy = 0.6812\n",
      "Batch 260: Loss = 0.9671, Accuracy = 0.6812\n",
      "Batch 270: Loss = 0.9676, Accuracy = 0.6807\n",
      "Batch 280: Loss = 0.9663, Accuracy = 0.6813\n",
      "Batch 290: Loss = 0.9668, Accuracy = 0.6806\n",
      "Batch 300: Loss = 0.9674, Accuracy = 0.6800\n",
      "Training - Loss: 0.9682, Accuracy: 0.6798\n",
      "Validation - Loss: 0.7690, Accuracy: 0.7576\n",
      "Epoch 28/30\n",
      "Batch 10: Loss = 0.9700, Accuracy = 0.6844\n",
      "Batch 20: Loss = 0.9438, Accuracy = 0.6922\n",
      "Batch 30: Loss = 0.9676, Accuracy = 0.6771\n",
      "Batch 40: Loss = 0.9910, Accuracy = 0.6797\n",
      "Batch 50: Loss = 0.9696, Accuracy = 0.6850\n",
      "Batch 60: Loss = 0.9719, Accuracy = 0.6839\n",
      "Batch 70: Loss = 0.9759, Accuracy = 0.6839\n",
      "Batch 80: Loss = 0.9766, Accuracy = 0.6863\n",
      "Batch 90: Loss = 0.9798, Accuracy = 0.6833\n",
      "Batch 100: Loss = 0.9804, Accuracy = 0.6800\n",
      "Batch 110: Loss = 0.9789, Accuracy = 0.6815\n",
      "Batch 120: Loss = 0.9749, Accuracy = 0.6839\n",
      "Batch 130: Loss = 0.9725, Accuracy = 0.6861\n",
      "Batch 140: Loss = 0.9734, Accuracy = 0.6857\n",
      "Batch 150: Loss = 0.9692, Accuracy = 0.6856\n",
      "Batch 160: Loss = 0.9741, Accuracy = 0.6830\n",
      "Batch 170: Loss = 0.9708, Accuracy = 0.6844\n",
      "Batch 180: Loss = 0.9744, Accuracy = 0.6847\n",
      "Batch 190: Loss = 0.9676, Accuracy = 0.6870\n",
      "Batch 200: Loss = 0.9671, Accuracy = 0.6864\n",
      "Batch 210: Loss = 0.9695, Accuracy = 0.6845\n",
      "Batch 220: Loss = 0.9747, Accuracy = 0.6814\n",
      "Batch 230: Loss = 0.9667, Accuracy = 0.6837\n",
      "Batch 240: Loss = 0.9645, Accuracy = 0.6850\n",
      "Batch 250: Loss = 0.9658, Accuracy = 0.6849\n",
      "Batch 260: Loss = 0.9699, Accuracy = 0.6811\n",
      "Batch 270: Loss = 0.9628, Accuracy = 0.6844\n",
      "Batch 280: Loss = 0.9665, Accuracy = 0.6823\n",
      "Batch 290: Loss = 0.9710, Accuracy = 0.6802\n",
      "Batch 300: Loss = 0.9732, Accuracy = 0.6797\n",
      "Training - Loss: 0.9721, Accuracy: 0.6798\n",
      "Validation - Loss: 0.7630, Accuracy: 0.7554\n",
      "Epoch 29/30\n",
      "Batch 10: Loss = 0.8827, Accuracy = 0.6969\n",
      "Batch 20: Loss = 0.9277, Accuracy = 0.6891\n",
      "Batch 30: Loss = 0.9302, Accuracy = 0.6927\n",
      "Batch 40: Loss = 0.9173, Accuracy = 0.6930\n",
      "Batch 50: Loss = 0.9332, Accuracy = 0.6900\n",
      "Batch 60: Loss = 0.9339, Accuracy = 0.6911\n",
      "Batch 70: Loss = 0.9306, Accuracy = 0.6920\n",
      "Batch 80: Loss = 0.9424, Accuracy = 0.6871\n",
      "Batch 90: Loss = 0.9305, Accuracy = 0.6906\n",
      "Batch 100: Loss = 0.9343, Accuracy = 0.6913\n",
      "Batch 110: Loss = 0.9312, Accuracy = 0.6940\n",
      "Batch 120: Loss = 0.9402, Accuracy = 0.6914\n",
      "Batch 130: Loss = 0.9458, Accuracy = 0.6887\n",
      "Batch 140: Loss = 0.9453, Accuracy = 0.6888\n",
      "Batch 150: Loss = 0.9495, Accuracy = 0.6865\n",
      "Batch 160: Loss = 0.9517, Accuracy = 0.6850\n",
      "Batch 170: Loss = 0.9492, Accuracy = 0.6855\n",
      "Batch 180: Loss = 0.9497, Accuracy = 0.6849\n",
      "Batch 190: Loss = 0.9432, Accuracy = 0.6868\n",
      "Batch 200: Loss = 0.9441, Accuracy = 0.6859\n",
      "Batch 210: Loss = 0.9480, Accuracy = 0.6848\n",
      "Batch 220: Loss = 0.9533, Accuracy = 0.6845\n",
      "Batch 230: Loss = 0.9537, Accuracy = 0.6852\n",
      "Batch 240: Loss = 0.9542, Accuracy = 0.6846\n",
      "Batch 250: Loss = 0.9537, Accuracy = 0.6851\n",
      "Batch 260: Loss = 0.9555, Accuracy = 0.6846\n",
      "Batch 270: Loss = 0.9579, Accuracy = 0.6834\n",
      "Batch 280: Loss = 0.9605, Accuracy = 0.6836\n",
      "Batch 290: Loss = 0.9542, Accuracy = 0.6852\n",
      "Batch 300: Loss = 0.9531, Accuracy = 0.6854\n",
      "Training - Loss: 0.9548, Accuracy: 0.6850\n",
      "Validation - Loss: 0.7664, Accuracy: 0.7702\n",
      "Epoch 30/30\n",
      "Batch 10: Loss = 0.9821, Accuracy = 0.6969\n",
      "Batch 20: Loss = 0.9754, Accuracy = 0.6812\n",
      "Batch 30: Loss = 0.9768, Accuracy = 0.6844\n",
      "Batch 40: Loss = 0.9822, Accuracy = 0.6773\n",
      "Batch 50: Loss = 0.9694, Accuracy = 0.6850\n",
      "Batch 60: Loss = 0.9690, Accuracy = 0.6802\n",
      "Batch 70: Loss = 0.9574, Accuracy = 0.6857\n",
      "Batch 80: Loss = 0.9619, Accuracy = 0.6832\n",
      "Batch 90: Loss = 0.9514, Accuracy = 0.6837\n",
      "Batch 100: Loss = 0.9456, Accuracy = 0.6825\n",
      "Batch 110: Loss = 0.9570, Accuracy = 0.6793\n",
      "Batch 120: Loss = 0.9551, Accuracy = 0.6805\n",
      "Batch 130: Loss = 0.9639, Accuracy = 0.6800\n",
      "Batch 140: Loss = 0.9660, Accuracy = 0.6801\n",
      "Batch 150: Loss = 0.9690, Accuracy = 0.6800\n",
      "Batch 160: Loss = 0.9682, Accuracy = 0.6807\n",
      "Batch 170: Loss = 0.9682, Accuracy = 0.6809\n",
      "Batch 180: Loss = 0.9689, Accuracy = 0.6797\n",
      "Batch 190: Loss = 0.9739, Accuracy = 0.6773\n",
      "Batch 200: Loss = 0.9724, Accuracy = 0.6761\n",
      "Batch 210: Loss = 0.9743, Accuracy = 0.6754\n",
      "Batch 220: Loss = 0.9695, Accuracy = 0.6766\n",
      "Batch 230: Loss = 0.9680, Accuracy = 0.6777\n",
      "Batch 240: Loss = 0.9682, Accuracy = 0.6781\n",
      "Batch 250: Loss = 0.9685, Accuracy = 0.6790\n",
      "Batch 260: Loss = 0.9669, Accuracy = 0.6790\n",
      "Batch 270: Loss = 0.9671, Accuracy = 0.6775\n",
      "Batch 280: Loss = 0.9686, Accuracy = 0.6764\n",
      "Batch 290: Loss = 0.9679, Accuracy = 0.6757\n",
      "Batch 300: Loss = 0.9680, Accuracy = 0.6766\n",
      "Training - Loss: 0.9673, Accuracy: 0.6763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.7694, Accuracy: 0.7632\n",
      "Test - Loss: 0.6872, Accuracy: 0.7740\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Custom ImageDataGenerator class\n",
    "class CustomImageDataGenerator(ImageDataGenerator):\n",
    "    def flow_from_directory(self, directory, *args, **kwargs):\n",
    "        generator = super().flow_from_directory(directory, *args, **kwargs)\n",
    "        self.target_size = kwargs.get('target_size', (224, 224))\n",
    "        self.num_classes = generator.num_classes\n",
    "        self.filepaths = generator.filepaths\n",
    "        self.labels = generator.classes\n",
    "        return generator\n",
    "\n",
    "# Data Generators\n",
    "train_datagen = CustomImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True\n",
    ")\n",
    "\n",
    "valid_datagen = CustomImageDataGenerator()\n",
    "test_datagen = CustomImageDataGenerator()\n",
    "\n",
    "# Directories for subset data\n",
    "train_subset_dir = \"/Users/Barbara/Downloads/food11/training\"\n",
    "val_subset_dir = \"/Users/Barbara/Downloads/food11/validation\"\n",
    "test_subset_dir = \"/Users/Barbara/Downloads/food11/evaluation\"\n",
    "\n",
    "# Generators\n",
    "train_generator = train_datagen.flow_from_directory(train_subset_dir, target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
    "valid_generator = valid_datagen.flow_from_directory(val_subset_dir, target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
    "test_generator = test_datagen.flow_from_directory(test_subset_dir, target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
    "\n",
    "# Get the number of classes from the train generator\n",
    "num_classes = train_generator.num_classes\n",
    "\n",
    "# Load the VGG16 model without the top layers and add custom layers\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the layers of the VGG16 base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Convert generators to tf.data.Dataset\n",
    "def generator_to_tfdata(generator):\n",
    "    def gen():\n",
    "        for x_batch, y_batch in generator:\n",
    "            yield x_batch, y_batch\n",
    "\n",
    "    return tf.data.Dataset.from_generator(gen, (tf.float32, tf.float32))\n",
    "\n",
    "# Convert generators to tf.data.Dataset with prefetching and better optimization\n",
    "train_dataset = generator_to_tfdata(train_generator).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "valid_dataset = generator_to_tfdata(valid_generator).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = generator_to_tfdata(test_generator).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# Custom training loop\n",
    "num_epochs = 30\n",
    "batch_size = 32\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, x_batch, y_batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(x_batch, training=True)\n",
    "        loss = tf.keras.losses.categorical_crossentropy(y_batch, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    model.optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss, predictions\n",
    "\n",
    "@tf.function\n",
    "def valid_step(model, x_batch, y_batch):\n",
    "    predictions = model(x_batch, training=False)\n",
    "    loss = tf.keras.losses.categorical_crossentropy(y_batch, predictions)\n",
    "    return loss, predictions\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    # Training\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "    train_batches = 0\n",
    "    \n",
    "    for x_batch, y_batch in train_dataset:\n",
    "        loss, predictions = train_step(model, x_batch, y_batch)\n",
    "        train_loss += tf.reduce_mean(loss)\n",
    "        train_accuracy += tf.reduce_mean(tf.keras.metrics.categorical_accuracy(y_batch, predictions))\n",
    "        train_batches += 1\n",
    "        \n",
    "        if train_batches % 10 == 0:\n",
    "            print(f\"Batch {train_batches}: Loss = {train_loss/train_batches:.4f}, Accuracy = {train_accuracy/train_batches:.4f}\")\n",
    "        if train_batches >= len(train_generator):  # Ensure loop breaks after all batches are processed\n",
    "            break\n",
    "    \n",
    "    train_loss /= train_batches\n",
    "    train_accuracy /= train_batches\n",
    "    print(f\"Training - Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.4f}\")\n",
    "    \n",
    "    # Validation\n",
    "    val_loss = 0\n",
    "    val_accuracy = 0\n",
    "    val_batches = 0\n",
    "    \n",
    "    for x_batch, y_batch in valid_dataset:\n",
    "        loss, predictions = valid_step(model, x_batch, y_batch)\n",
    "        val_loss += tf.reduce_mean(loss)\n",
    "        val_accuracy += tf.reduce_mean(tf.keras.metrics.categorical_accuracy(y_batch, predictions))\n",
    "        val_batches += 1\n",
    "    \n",
    "        if val_batches >= len(valid_generator):  # Ensure loop breaks after all batches are processed\n",
    "            break\n",
    "    \n",
    "    val_loss /= val_batches\n",
    "    val_accuracy /= val_batches\n",
    "    print(f\"Validation - Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "# Save the model\n",
    "model.save('/Users/Barbara/Desktop/Ironhack/Final_Project/food_recognition_model4.h5')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss = 0\n",
    "test_accuracy = 0\n",
    "test_batches = 0\n",
    "all_predictions = []\n",
    "all_true_labels = []\n",
    "\n",
    "for x_batch, y_batch in test_dataset:\n",
    "    loss, predictions = valid_step(model, x_batch, y_batch)\n",
    "    test_loss += tf.reduce_mean(loss)\n",
    "    test_accuracy += tf.reduce_mean(tf.keras.metrics.categorical_accuracy(y_batch, predictions))\n",
    "    \n",
    "    all_predictions.extend(np.argmax(predictions, axis=1))\n",
    "    all_true_labels.extend(np.argmax(y_batch, axis=1))\n",
    "    \n",
    "    test_batches += 1\n",
    "\n",
    "    if test_batches >= len(test_generator):  # Ensure loop breaks after all batches are processed\n",
    "        break\n",
    "\n",
    "test_loss /= test_batches\n",
    "test_accuracy /= test_batches\n",
    "print(f\"Test - Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3347 images belonging to 11 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-11 12:44:33.172102: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Pro\n",
      "2024-07-11 12:44:33.172128: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 18.00 GB\n",
      "2024-07-11 12:44:33.172134: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 6.00 GB\n",
      "2024-07-11 12:44:33.172148: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-07-11 12:44:33.172158: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "2024-07-11 12:44:33.533416: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "/Applications/Utilities/anaconda3/envs/tensorflow_macos/lib/python3.9/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 198ms/step - accuracy: 0.6757 - loss: 0.9397\n",
      "Overall Test Loss: 0.6860\n",
      "Overall Test Accuracy: 0.7747\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 189ms/step\n",
      "Class-wise Accuracy:\n",
      "Accuracy for class Bread: 0.70\n",
      "Accuracy for class Dairy product: 0.80\n",
      "Accuracy for class Dessert: 0.72\n",
      "Accuracy for class Egg: 0.68\n",
      "Accuracy for class Fried food: 0.84\n",
      "Accuracy for class Meat: 0.66\n",
      "Accuracy for class Noodles-Pasta: 0.96\n",
      "Accuracy for class Rice: 0.90\n",
      "Accuracy for class Seafood: 0.76\n",
      "Accuracy for class Soup: 0.93\n",
      "Accuracy for class Vegetable-Fruit: 0.85\n",
      "\n",
      "Full Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          Bread       0.70      0.62      0.66       368\n",
      "  Dairy product       0.80      0.45      0.57       148\n",
      "        Dessert       0.72      0.71      0.71       500\n",
      "            Egg       0.68      0.67      0.68       335\n",
      "     Fried food       0.84      0.60      0.70       287\n",
      "           Meat       0.66      0.90      0.76       432\n",
      "  Noodles-Pasta       0.96      0.94      0.95       147\n",
      "           Rice       0.90      0.88      0.89        96\n",
      "        Seafood       0.76      0.83      0.80       303\n",
      "           Soup       0.93      0.95      0.94       500\n",
      "Vegetable-Fruit       0.85      0.91      0.88       212\n",
      "\n",
      "       accuracy                           0.77      3328\n",
      "      macro avg       0.80      0.77      0.78      3328\n",
      "   weighted avg       0.78      0.77      0.77      3328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Custom ImageDataGenerator class\n",
    "class CustomImageDataGenerator(ImageDataGenerator):\n",
    "    def flow_from_directory(self, directory, *args, **kwargs):\n",
    "        generator = super().flow_from_directory(directory, *args, **kwargs)\n",
    "        self.target_size = kwargs.get('target_size', (224, 224))\n",
    "        self.num_classes = generator.num_classes\n",
    "        self.filepaths = generator.filepaths\n",
    "        self.labels = generator.classes\n",
    "        return generator\n",
    "\n",
    "# Directories for subset data\n",
    "test_subset_dir = \"/Users/Barbara/Downloads/food11/evaluation\"\n",
    "\n",
    "# Data Generators\n",
    "test_datagen = CustomImageDataGenerator()\n",
    "test_generator = test_datagen.flow_from_directory(test_subset_dir, target_size=(224, 224), batch_size=32, class_mode='categorical', shuffle=False)\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model('/Users/Barbara/Desktop/Ironhack/Final_Project/food_recognition_model4.h5')\n",
    "\n",
    "# Use model.evaluate to get the loss and accuracy\n",
    "loss, accuracy = model.evaluate(test_generator)\n",
    "print(f\"Overall Test Loss: {loss:.4f}\")\n",
    "print(f\"Overall Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Get predictions and true labels in one pass\n",
    "test_steps = test_generator.samples // test_generator.batch_size\n",
    "predictions = model.predict(test_generator, steps=test_steps)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = test_generator.classes[:test_steps * test_generator.batch_size]\n",
    "\n",
    "# Calculate and print classification report\n",
    "target_names = list(test_generator.class_indices.keys())\n",
    "report = classification_report(true_classes, predicted_classes, target_names=target_names, output_dict=True)\n",
    "\n",
    "# Calculate accuracy for each class\n",
    "accuracies = {}\n",
    "for label, metrics in report.items():\n",
    "    if label not in target_names:\n",
    "        continue\n",
    "    accuracies[label] = metrics['precision']  # Using precision as class accuracy\n",
    "\n",
    "# Print accuracy for each class\n",
    "print(\"Class-wise Accuracy:\")\n",
    "for class_name, accuracy in accuracies.items():\n",
    "    print(f\"Accuracy for class {class_name}: {accuracy:.2f}\")\n",
    "\n",
    "# Optional: Print the full classification report for additional details\n",
    "print(\"\\nFull Classification Report:\")\n",
    "print(classification_report(true_classes, predicted_classes, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = classification_report(true_classes, predicted_classes, target_names=target_names, output_dict=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "metrics = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bread</th>\n",
       "      <th>Dairy product</th>\n",
       "      <th>Dessert</th>\n",
       "      <th>Egg</th>\n",
       "      <th>Fried food</th>\n",
       "      <th>Meat</th>\n",
       "      <th>Noodles-Pasta</th>\n",
       "      <th>Rice</th>\n",
       "      <th>Seafood</th>\n",
       "      <th>Soup</th>\n",
       "      <th>Vegetable-Fruit</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.704969</td>\n",
       "      <td>0.795181</td>\n",
       "      <td>0.716298</td>\n",
       "      <td>0.676647</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.663823</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.927451</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.773738</td>\n",
       "      <td>0.800549</td>\n",
       "      <td>0.779535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.616848</td>\n",
       "      <td>0.445946</td>\n",
       "      <td>0.712000</td>\n",
       "      <td>0.674627</td>\n",
       "      <td>0.599303</td>\n",
       "      <td>0.900463</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.831683</td>\n",
       "      <td>0.946000</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.773738</td>\n",
       "      <td>0.767846</td>\n",
       "      <td>0.773738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.657971</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.714142</td>\n",
       "      <td>0.675635</td>\n",
       "      <td>0.700611</td>\n",
       "      <td>0.764244</td>\n",
       "      <td>0.948454</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.796209</td>\n",
       "      <td>0.936634</td>\n",
       "      <td>0.878719</td>\n",
       "      <td>0.773738</td>\n",
       "      <td>0.775721</td>\n",
       "      <td>0.769818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>368.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>287.000000</td>\n",
       "      <td>432.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>0.773738</td>\n",
       "      <td>3328.000000</td>\n",
       "      <td>3328.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Bread  Dairy product     Dessert         Egg  Fried food  \\\n",
       "precision    0.704969       0.795181    0.716298    0.676647    0.843137   \n",
       "recall       0.616848       0.445946    0.712000    0.674627    0.599303   \n",
       "f1-score     0.657971       0.571429    0.714142    0.675635    0.700611   \n",
       "support    368.000000     148.000000  500.000000  335.000000  287.000000   \n",
       "\n",
       "                 Meat  Noodles-Pasta       Rice     Seafood        Soup  \\\n",
       "precision    0.663823       0.958333   0.903226    0.763636    0.927451   \n",
       "recall       0.900463       0.938776   0.875000    0.831683    0.946000   \n",
       "f1-score     0.764244       0.948454   0.888889    0.796209    0.936634   \n",
       "support    432.000000     147.000000  96.000000  303.000000  500.000000   \n",
       "\n",
       "           Vegetable-Fruit  accuracy    macro avg  weighted avg  \n",
       "precision         0.853333  0.773738     0.800549      0.779535  \n",
       "recall            0.905660  0.773738     0.767846      0.773738  \n",
       "f1-score          0.878719  0.773738     0.775721      0.769818  \n",
       "support         212.000000  0.773738  3328.000000   3328.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the DataFrame\n",
    "data = {\n",
    "    'Food Category': ['Bread', 'Dairy product', 'Dessert', 'Egg', 'Fried food', 'Meat', 'Noodles-Pasta', 'Rice', 'Seafood', 'Soup', 'Vegetable-Fruit', 'accuracy', 'macro avg', 'weighted avg'],\n",
    "    'precision': [0.704969, 0.795181, 0.716298, 0.676647, 0.843137, 0.663823, 0.958333, 0.903226, 0.763636, 0.927451, 0.853333, 0.773738, 0.800549, 0.779535],\n",
    "    'recall': [0.616848, 0.445946, 0.712000, 0.674627, 0.599303, 0.900463, 0.938776, 0.875000, 0.831683, 0.946000, 0.905660, 0.773738, 0.767846, 0.773738],\n",
    "    'f1-score': [0.657971, 0.571429, 0.714142, 0.675635, 0.700611, 0.764244, 0.948454, 0.888889, 0.796209, 0.936634, 0.878719, 0.773738, 0.775721, 0.769818],\n",
    "    'support': [368, 148, 500, 335, 287, 432, 147, 96, 303, 500, 212, 0.773738, 3328, 3328]\n",
    "}\n",
    "\n",
    "df_metrics = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Food Category</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bread</td>\n",
       "      <td>0.704969</td>\n",
       "      <td>0.616848</td>\n",
       "      <td>0.657971</td>\n",
       "      <td>368.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dairy product</td>\n",
       "      <td>0.795181</td>\n",
       "      <td>0.445946</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>148.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dessert</td>\n",
       "      <td>0.716298</td>\n",
       "      <td>0.712000</td>\n",
       "      <td>0.714142</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Egg</td>\n",
       "      <td>0.676647</td>\n",
       "      <td>0.674627</td>\n",
       "      <td>0.675635</td>\n",
       "      <td>335.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fried food</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.599303</td>\n",
       "      <td>0.700611</td>\n",
       "      <td>287.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Meat</td>\n",
       "      <td>0.663823</td>\n",
       "      <td>0.900463</td>\n",
       "      <td>0.764244</td>\n",
       "      <td>432.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Noodles-Pasta</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.948454</td>\n",
       "      <td>147.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rice</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>96.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Seafood</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.831683</td>\n",
       "      <td>0.796209</td>\n",
       "      <td>303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Soup</td>\n",
       "      <td>0.927451</td>\n",
       "      <td>0.946000</td>\n",
       "      <td>0.936634</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Vegetable-Fruit</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.878719</td>\n",
       "      <td>212.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.773738</td>\n",
       "      <td>0.773738</td>\n",
       "      <td>0.773738</td>\n",
       "      <td>0.773738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.800549</td>\n",
       "      <td>0.767846</td>\n",
       "      <td>0.775721</td>\n",
       "      <td>3328.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>0.779535</td>\n",
       "      <td>0.773738</td>\n",
       "      <td>0.769818</td>\n",
       "      <td>3328.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Food Category  precision    recall  f1-score      support\n",
       "0             Bread   0.704969  0.616848  0.657971   368.000000\n",
       "1     Dairy product   0.795181  0.445946  0.571429   148.000000\n",
       "2           Dessert   0.716298  0.712000  0.714142   500.000000\n",
       "3               Egg   0.676647  0.674627  0.675635   335.000000\n",
       "4        Fried food   0.843137  0.599303  0.700611   287.000000\n",
       "5              Meat   0.663823  0.900463  0.764244   432.000000\n",
       "6     Noodles-Pasta   0.958333  0.938776  0.948454   147.000000\n",
       "7              Rice   0.903226  0.875000  0.888889    96.000000\n",
       "8           Seafood   0.763636  0.831683  0.796209   303.000000\n",
       "9              Soup   0.927451  0.946000  0.936634   500.000000\n",
       "10  Vegetable-Fruit   0.853333  0.905660  0.878719   212.000000\n",
       "11         accuracy   0.773738  0.773738  0.773738     0.773738\n",
       "12        macro avg   0.800549  0.767846  0.775721  3328.000000\n",
       "13     weighted avg   0.779535  0.773738  0.769818  3328.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics.to_csv('metrics.csv',index=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[227,   0,  26,  40,  17,  38,   0,   2,  13,   4,   1],\n",
       "       [  8,  66,  44,   5,   3,   9,   0,   0,   7,   4,   2],\n",
       "       [ 13,  10, 356,  28,   4,  45,   1,   1,  17,  15,  10],\n",
       "       [ 39,   1,  14, 226,   3,  27,   1,   3,  14,   2,   5],\n",
       "       [ 23,   3,  21,   8, 172,  46,   0,   1,  11,   1,   1],\n",
       "       [  7,   0,  14,   7,   3, 389,   1,   0,   7,   4,   0],\n",
       "       [  0,   0,   0,   4,   1,   0, 138,   0,   0,   1,   3],\n",
       "       [  1,   0,   1,   1,   0,   1,   1,  84,   1,   2,   4],\n",
       "       [  2,   1,   9,  10,   0,  17,   1,   1, 252,   4,   6],\n",
       "       [  1,   1,  10,   2,   0,   8,   0,   1,   3, 473,   1],\n",
       "       [  1,   1,   2,   3,   1,   6,   1,   0,   5,   0, 192]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true=true_classes, y_pred=predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_classes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 images belonging to 3 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 109 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x3125d8a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 109 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x3125d8a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step\n",
      "Class-wise Accuracy:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Custom ImageDataGenerator class\n",
    "class CustomImageDataGenerator(ImageDataGenerator):\n",
    "    def flow_from_directory(self, directory, *args, **kwargs):\n",
    "        generator = super().flow_from_directory(directory, *args, **kwargs)\n",
    "        self.target_size = kwargs.get('target_size', (224, 224))\n",
    "        self.num_classes = generator.num_classes\n",
    "        self.filepaths = generator.filepaths\n",
    "        self.labels = generator.classes\n",
    "        return generator\n",
    "\n",
    "# Directories for subset data\n",
    "test_subset_dir = \"/Users/Barbara/Downloads/food11/bread\"\n",
    "\n",
    "# Data Generators\n",
    "test_datagen = CustomImageDataGenerator()\n",
    "test_generator = test_datagen.flow_from_directory(test_subset_dir, target_size=(224, 224), batch_size=32, class_mode='categorical', shuffle=False)\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model('/Users/Barbara/Desktop/Ironhack/Final_Project/food_recognition_model4.h5')\n",
    "\n",
    "# Use model.evaluate to get the loss and accuracy\n",
    "\n",
    "\n",
    "# Get predictions and true labels in one pass\n",
    "test_steps = test_generator.samples // test_generator.batch_size\n",
    "predictions = model.predict(test_generator, steps=test_steps)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = test_generator.classes[:test_steps * test_generator.batch_size]\n",
    "\n",
    "\n",
    "\n",
    "# Calculate accuracy for each class\n",
    "accuracies = {}\n",
    "for label, metrics in report.items():\n",
    "    if label not in target_names:\n",
    "        continue\n",
    "    accuracies[label] = metrics['precision']  # Using precision as class accuracy\n",
    "\n",
    "# Print accuracy for each class\n",
    "print(\"Class-wise Accuracy:\")\n",
    "for class_name, accuracy in accuracies.items():\n",
    "    print(f\"Accuracy for class {class_name}: {accuracy:.2f}\")\n",
    "\n",
    "predicted_classes\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_macos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
